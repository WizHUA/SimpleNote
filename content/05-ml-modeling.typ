#import "../template.typ": *

= 机器学习建模与性能预测

基于前文所构建的标准化数据集，本部分设计并实现集合通信算法性能预测的机器学习模型。具体而言，本章节通过理论复杂度分析指导建模方案，并通过对比多种回归算法，选择最适合该问题的模型架构，并进行系统的参数优化。

== 理论复杂度分析对建模的指导

=== 复杂度理论与特征关系

基于#link(<summary>)[第2章源码分析]中的算法复杂度总结，以Reduce操作为例分析理论复杂度与实际性能的关系：

#figure(
  table(
    columns: (1.8fr, 2fr, 1.5fr, 2fr),
    align: (left, left, center, left),
    stroke: 0.5pt,
    table.header([*算法类型*], [*理论复杂度*], [*主导因子*], [*性能特征*]),
    
    [二项式树], [$O(α log(p) + β m)$], [$log(p), m$], [延迟随进程数对数增长],
    [K项树], [$O(α log_k(p) + β m)$], [$log_k(p), m$], [k值影响通信轮数],
    [线性算法], [$O((p-1)α + (p-1)β m)$], [$p, m$], [延迟随进程数线性增长],
    [链式算法], [$O(p/"fanout" α + β m)$], [$p/"fanout", m$], [扇出参数影响并行度]
  ),
  caption: [算法复杂度与性能特征对应关系]
)

从复杂度分析可以得出以下建模指导：

*特征重要性预期*：
1. *消息大小* $m$：在所有算法中都是线性主导因子，应为最重要特征
2. *进程数* $p$：不同算法对进程数的敏感度不同（线性 vs 对数），应为关键区分特征
3. *算法参数*：如$k$（树的分支数）、fanout等直接影响复杂度系数

*非线性关系*：
- 不同算法在相同环境下的性能差异可能很大（线性 vs 对数复杂度）
- 参数配置对性能的影响呈现非线性特征（如$log_k(p)$中的$k$值选择）

=== 复杂度指导的增强特征

基于上述分析，设计增强特征以反映复杂度关系：

```python
def create_complexity_features(df):
    """基于复杂度理论创建增强特征"""
    # 基础特征
    df['log_comm_size'] = np.log2(df['comm_size'])  # 对数复杂度特征
    df['linear_comm_size'] = df['comm_size']        # 线性复杂度特征
    
    # 算法-环境交互特征
    df['msg_size_comm_interaction'] = df['msg_size_log'] * df['log_comm_size']
    
    # 基于算法类型的复杂度特征
    for idx, row in df.iterrows():
        op = row['operation']
        alg_id = row['algorithm_id']
        
        # 根据算法类型预测复杂度主导项
        if op == 'reduce':
            if alg_id == 6:  # 线性算法
                df.at[idx, 'expected_complexity'] = row['comm_size'] * row['msg_size_log']
            else:  # 树形算法
                df.at[idx, 'expected_complexity'] = row['log_comm_size'] + row['msg_size_log']
    
    return df
```

== 三种建模方案设计

=== 方案对比分析

针对集合通信算法选择问题，基于#link(<summary>)[第3章源码分析]中的复杂度理论，设计三种不同的建模方案：

#figure(
  table(
    columns: (1.5fr, 2fr, 2fr, 2fr, 1.5fr),
    align: (left, left, left, left, center),
    stroke: 0.5pt,
    table.header([*方案*], [*问题类型*], [*输入*], [*输出*], [*复杂度特点*]),
    
    [回归预测], [回归问题], [环境+配置特征], [延迟时间], [捕获连续性能关系],
    [分类决策], [多分类问题], [环境特征], [最优配置ID], [学习离散决策边界],
    [混合建模], [分类+回归], [环境特征], [算法类别+参数], [分层优化策略],
  ),
  caption: [三种建模方案对比]
)

=== 方案一：回归预测模型

==== 数学建模

将集合通信算法选择问题建模为连续函数逼近问题：

给定输入特征向量 $bold(x) = (bold(x)_("env"), bold(x)_("config"))$，其中：
- $bold(x)_("env") = (n_("encoded"), m_("log"), "op"_("encoded")) in bb(R)^7$ 为环境特征
- $bold(x)_("config") = ("alg"_("encoded"), bold(p)_("encoded")) in bb(R)^6$ 为配置特征

目标函数为：
$ f_("reg"): bb(R)^13 -> bb(R)^+ $
$ hat(t) = f_("reg")(bold(x)_("env"), bold(x)_("config"); theta_("reg")) $

其中 $hat(t)$ 为预测的通信延迟，$theta_("reg")$ 为模型参数。

==== 理论复杂度指导

基于源码分析中的算法复杂度，增强所得特征的数学性质：

*线性复杂度特征*：对于线性算法（如basic_linear），延迟主要受进程数线性影响：
$ f_("linear")(n, m) = alpha_1 n + beta_1 m + gamma_1 $

*对数复杂度特征*：对于树形算法（如binomial、knomial），延迟受进程数对数影响：
$ f_("tree")(n, m, k) = alpha_2 log_k(n) + beta_2 m + gamma_2 $

*交互复杂度特征*：消息大小与通信轮数的交互效应：
$ f_("interaction")(n, m) = alpha_3 m dot log(n) + beta_3 $

因此，设计增强特征向量：
$ bold(x)_("enhanced") = (bold(x)_("env"), bold(x)_("config"), n, log(n), m dot log(n)) $

==== 最优配置搜索

训练完成后，通过求解优化问题找到最优配置：

$ (bold(x)^*_("config")) = arg min_(bold(x)_("config") in Theta_("op")) f_("reg")(bold(x)_("env"), bold(x)_("config")) $

其中 $Theta_("op")$ 为给定操作的所有有效配置空间。

==== 方案分析

*理论优势*：
- 能够建模连续的性能-配置关系，理论精度上限最高
- 充分利用复杂度理论，可解释性强
- 支持任意配置的性能预测和置信区间估计

*实际局限*：
- 推理时需遍历配置空间 $|Theta_("op")|$，计算复杂度为 $O(|Theta_("op")|)$
- 对于Reduce操作的93种配置，搜索开销较大
- 同时可能由于测量误差难以取得精确的预测效果，给最终决策带来显著误差

=== 方案二：分类决策模型

==== 数学建模

将算法选择问题建模为多分类决策问题：

给定环境特征 $bold(x)_("env") = (n_("encoded"), m_("log"), "op"_("encoded")) in bb(R)^7$，直接预测最优配置：

$ g_("cls"): bb(R)^7 -> cal(C)_("op") $
$ c^* = g_("cls")(bold(x)_("env"); theta_("cls")) $

其中 $cal(C)_("op")$ 为操作op的配置标签空间，$c^*$ 为预测的最优配置标签。

==== 决策边界理论

#let add = [
  此处依据为源码中的注释，在前文复杂度分析中也有提及。
]

基于算法复杂度差异，不同配置的最优性呈现分段特征：

*小规模区域*：当 $n <= n_0$ 且 $m <= m_0$ 时，线性算法可能最优：
$ c^* = arg min_(c in cal(C)_("linear")) T(n, m, c) $

*大规模区域*：当 $n > n_0$ 或 $m > m_0$ 时，树形算法占优：
$ c^* = arg min_(c in cal(C)_("tree")) T(n, m, c) $

分类模型学习这些决策边界：
$ P(c^* = c_i | bold(x)_("env")) = "softmax"(bold(W) bold(x)_("env") + bold(b))_i $

==== 标签构造策略

对于每个环境 $(n, m, "op")$，通过下述公式确定最优配置标签：

$ c^*_(n,m,"op") = arg min_(c in cal(C)_("op")) E[T(n, m, "op", c)] $

其中期望通过重复测量估计：
$ E[T(n, m, "op", c)] approx frac(1, K) sum_(k=1)^K t^(k)_(n,m,"op",c) $

==== 方案分析

*理论优势*：
- 推理复杂度为 $O(1)$，实时决策效率高
- 学习环境到最优配置的直接映射，避免搜索过程
- 决策边界可视化，便于理解算法选择规律

*实际局限*：
- 只能预测训练集中出现的配置组合，泛化能力受限
- 无法提供性能数值预测，缺乏性能量化信息
- 对稀疏配置空间的处理能力较弱

=== 方案三：混合建模方案

==== 层次化建模

结合分类和回归优势，采用两阶段层次化决策（算法采用分类，配置进行回归）：

*第一阶段：算法类别选择*
$ g_1: bb(R)^7 -> cal(A)_("op") $
$ a^* = g_1(bold(x)_("env"); theta_1) $

其中 $cal(A)_("op")$ 为操作op的算法类别空间。

*第二阶段：参数优化*
对于选定算法 $a^*$，求解参数优化子问题：
$ g_2^(a^*): bb(R)^7 times bb(R)^(|cal(P)_(a^*)|) -> bb(R)^+ $
$ bold(p)^* = arg min_(bold(p) in cal(P)_(a^*)) g_2^(a^*)(bold(x)_("env"), bold(p); theta_2^(a^*)) $

==== 复杂度分解理论

基于算法复杂度的层次结构，将优化问题分解：

*算法层复杂度*：不同算法类别具有本质不同的复杂度特征
- 线性类：$T_("linear") = O(n dot m)$
- 树形类：$T_("tree") = O(log(n) dot m)$ 
- 分散聚集类：$T_("scatter-gather") = O(log(n) + m)$

*参数层复杂度*：在固定算法类别内，参数影响常数因子
- 树形参数：$T_("tree")(k) = alpha log_k(n) + beta m$
- 分段参数：$T_("segment")(s) = alpha log(n) + beta m/s + gamma s$

第一阶段学习算法类别的主导性：
$ P(a^* = a_i | bold(x)_("env")) prop exp(-lambda E[T_(a_i)(bold(x)_("env"))]) $

第二阶段在选定算法内优化参数：
$ bold(p)^* = arg min_(bold(p)} E[T_(a^*)(bold(x)_("env"), bold(p))] $


==== 方案优势分析

*计算效率*：第一阶段复杂度 $O(1)$，第二阶段复杂度 $O(|cal(P)_(a^*)|) << O(|Theta_("op")|)$

*精度平衡*：保留回归的参数优化能力，避免全空间搜索

*可解释性*：两阶段决策符合人类认知：先选算法类别，再调参数

在算法分类准确的前提下，性能接近全局最优

== 小结

本章基于理论复杂度分析，系统地设计了集合通信算法性能预测的机器学习建模方案。首先通过分析不同算法的复杂度特征，明确了消息大小作为线性主导因子的重要性，以及进程数在线性与对数复杂度间的区分作用，据此设计了包含对数复杂度特征和交互特征的增强特征工程方法。

在此基础上，针对算法选择问题的不同特点，提出了三种可能的建模方案：回归预测方案能够捕获精细的性能-配置关系但推理开销较大，分类决策方案实现了$O(1)$复杂度的实时决策但泛化能力受限，混合建模方案通过两阶段层次化决策在计算效率和预测精度间取得平衡。这三种方案分别适用于不同的应用需求，具体的表现将在后文中通过实验数据具体分析。

