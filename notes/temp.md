// ...existing code...

针对不同建模方案的特点，设计相应的评估指标：

*回归模型评估指标*：
- 均方根误差（RMSE）#footnote[均方根误差衡量预测值与真实值之间的差异程度，单位与原始数据相同，对大误差更敏感]：$"RMSE" = sqrt(frac(1, n) sum_(i=1)^n (hat(y)_i - y_i)^2)$
- 平均绝对百分比误差（MAPE）#footnote[平均绝对百分比误差表示预测误差占真实值的百分比，是无量纲指标，便于跨不同数据集对比]：$"MAPE" = frac(1, n) sum_(i=1)^n abs(frac(hat(y)_i - y_i, y_i)) times 100%$
- 决定系数（R²）#footnote[决定系数衡量模型能解释数据变异性的比例，范围[0,1]，越接近1表示模型拟合效果越好]：$R^2 = 1 - frac("SS"_("res"), "SS"_("tot"))$

*分类模型评估指标*：
- 准确率（Accuracy）#footnote[准确率是正确预测样本数占总样本数的比例，其中TP为真正例，TN为真负例，FP为假正例，FN为假负例]：$"Accuracy" = frac("TP" + "TN", "TP" + "TN" + "FP" + "FN")$
- 宏平均F1分数#footnote[宏平均F1分数对每个类别分别计算F1分数后取平均，能有效处理类别不平衡问题，其中F1分数是精确率和召回率的调和平均]：$"F1"_("macro") = frac(1, |C|) sum_(c in C) "F1"_c$
- Top-k准确率#footnote[Top-k准确率指预测的前k个最可能配置中包含真实最优配置的比例，对于算法选择问题具有实际意义]：预测的前k个最可能配置中包含真实最优配置的比例

*性能优化效果评估*：
- 相对性能提升#footnote[相对性能提升衡量相比基准方法（如默认配置或随机选择）的性能改善程度，是评估模型实际应用价值的重要指标]：$"Improvement" = frac(T_("baseline") - T_("predicted"), T_("baseline")) times 100%$
- 决策时延#footnote[决策时延是模型从接收输入到输出预测结果所需的时间，在在线优化场景下是关键性能指标]：模型推理所需的计算时间

// ...existing code...